import os
import pandas as pd
import numpy as np
import shutil
from sklearn.model_selection import train_test_split
import re # For extracting video ID from filenames

# --- Configuration Paths ---
# IMPORTANT: Update these paths to your actual data locations!

# Input: Root directory containing processed features CSVs and annotated images
# This should be the output from your processing_image_sequence.py
PROCESSED_DATA_ROOT = r'E:/User/my work/Summer project/Code/processed_data_output'

# Input: Path to your master labeled_data.csv
# This CSV contains original complex filenames and their labels
YOUR_LABELED_DATA_CSV = r'E:/User/my work/Summer project/Code/labeled_data.csv'

# Input: Root directory containing the _frame_map.csv files
# These are generated by Frame_Renaming_Staged.py, linking new_filename to original_filename
# This should be the output from your Frame_Renaming_Staged.py
RENAMED_DATASET_ROOT = r'E:/User/my work/Summer project/Code/data_preprocessing/RenamedDataset'

# Output: The final structured dataset for your CNN-LSTM model
# This folder will contain class_name/sequence_id/images/ and features.npy
FINAL_DATASET_ROOT = r'E:/User/my work/Summer project/Code/final_dataset_for_cnn_lstm'

# --- Sequence and Split Configuration ---
SEQUENCE_LENGTH = 10 # Number of frames per sequence
TRAIN_VAL_SPLIT_RATIO = 0.2 # Ratio for validation split from the *training* data
TEST_SPLIT_RATIO = 0.15 # Ratio for test split from the *total* unique video clips
RANDOM_SEED = 42 # For reproducibility of splits

# --- Function to extract video ID from your complex original_filename ---
# Example: 'surya_namaskaram_mp4-0000_jpg.rf.5ab047edd343545cade6e07bab88aa51.jpg' -> 'surya_namaskaram_mp4'
def extract_video_id(original_filename):
    # This regex looks for the part before '-0000_jpg' or '-000_jpg' pattern or similar
    match = re.match(r'(.+?)(-\d{4,5}_jpg|\.mp4)', original_filename)
    if match:
        # Take the part before the frame number/extension marker, and remove trailing '_mp4' if present
        return match.group(1).replace('_mp4', '')
    
    # Fallback: If no clear delimiter like '-0000_jpg', try to get the part before '.rf.'
    match_rf = re.match(r'(.+?)\.rf\.', original_filename)
    if match_rf:
        return match_rf.group(1).replace('_mp4', '') # Remove _mp4 suffix if present
    
    # If all else fails, use the whole filename prefix without extension and .rf part
    return original_filename.split('-0')[0].split('.rf.')[0].replace('_mp4', '').strip()

# --- Main Script Logic ---
def create_dataset_sequences(processed_data_root, labeled_csv_path, renamed_data_root, final_dataset_root):
    # Ensure output directory is clean
    if os.path.exists(final_dataset_root):
        shutil.rmtree(final_dataset_root)
    os.makedirs(final_dataset_root, exist_ok=True)

    print(f"Starting dataset sequence creation. Output will be in: {final_dataset_root}")

    # 1. Load your master labeled_data.csv
    try:
        df_labels = pd.read_csv(labeled_csv_path)
        df_labels['filename'] = df_labels['filename'].astype(str).str.strip()
        print(f"Loaded master labels from {labeled_csv_path}. Total entries: {len(df_labels)}")
    except FileNotFoundError:
        print(f"Error: labeled_data.csv not found at {labeled_csv_path}. Please check the path.")
        return
    
    # Create a lookup dictionary for labels: original_filename -> label
    label_lookup = df_labels.set_index('filename')['label'].to_dict()
    print(f"Created label lookup for {len(label_lookup)} original filenames.")

    # List to store all video clip information for splitting
    all_clip_infos = []

    # 2. Iterate through processed data and build a list of all clips
    for split_type in ['train', 'test', 'valid']: # Iterate through your data splits (train, test, valid)
        split_processed_path = os.path.join(processed_data_root, split_type)
        split_renamed_path = os.path.join(renamed_data_root, split_type) # Path to access _frame_map.csv
        
        if not os.path.exists(split_processed_path):
            print(f"Warning: Processed data path for {split_type} '{split_processed_path}' not found. Skipping.")
            continue
        if not os.path.exists(split_renamed_path):
            print(f"Warning: Renamed data path for {split_type} '{split_renamed_path}' not found. Cannot load _frame_map.csv. Skipping.")
            continue

        video_clip_dirs = sorted([d for d in os.listdir(split_processed_path) if os.path.isdir(os.path.join(split_processed_path, d)) and d.endswith('_annotated_images')])
        
        if not video_clip_dirs:
            print(f"No annotated image directories found in {split_processed_path}. Skipping {split_type} split.")
            continue

        print(f"\n--- Collecting clip info for {split_type} split ---")
        for annotated_images_dir_name in video_clip_dirs:
            clip_name = annotated_images_dir_name.replace('_annotated_images', '') # Get original clip name
            clip_processed_images_path = os.path.join(split_processed_path, annotated_images_dir_name)
            clip_features_csv_path = os.path.join(split_processed_path, f"{clip_name}_features.csv")
            
            # Path to the _frame_map.csv for this clip (from RENAMED_DATASET_ROOT)
            clip_frame_map_csv_path = os.path.join(split_renamed_path, clip_name, f"{clip_name}_frame_map.csv")


            if not os.path.exists(clip_features_csv_path) or not os.path.exists(clip_frame_map_csv_path):
                print(f"  Warning: Skipping clip '{clip_name}' due to missing features CSV or frame map CSV.")
                continue
            
            # Load features for this clip
            df_features = pd.read_csv(clip_features_csv_path)
            
            # Load frame map for this clip
            df_frame_map = pd.read_csv(clip_frame_map_csv_path)
            frame_map_lookup = df_frame_map.set_index('new_filename')['original_filename'].to_dict()

            # Add original_complex_filename to df_features using the map
            # The 'original_image_filename' in df_features is 'frame_0000x.jpg' from processing_image_sequence.py
            # We need to map this back to the 'long_original_filename' from labeled_data.csv
            df_features['long_original_filename'] = df_features['original_image_filename'].map(frame_map_lookup)

            # Get labels for each frame from the master labeled_data.csv
            df_features['label'] = df_features['long_original_filename'].map(label_lookup)

            # Drop frames that don't have a label (e.g., if you only partially labeled)
            df_features.dropna(subset=['label'], inplace=True)

            if df_features.empty:
                print(f"  Skipping clip '{clip_name}': No labeled frames found after linking.")
                continue

            # Extract unique video ID from original complex filename (first entry is sufficient if consistent)
            # This is crucial for splitting at the video clip level
            video_id = extract_video_id(df_features['long_original_filename'].iloc[0])

            all_clip_infos.append({
                'video_id': video_id,
                'clip_name': clip_name, # Name of the folder (e.g. video_clip_001)
                'split_type': split_type, # Original split (train/test/valid)
                'df_features': df_features, # DataFrame of features for this clip
                'clip_processed_images_path': clip_processed_images_path # Path to annotated images
            })
            print(f"  Collected clip '{clip_name}' (Video ID: {video_id}) with {len(df_features)} labeled frames.")

    if not all_clip_infos:
        print("No clips found with labeled frames to process. Exiting.")
        return

    # Get unique video IDs for the split
    unique_video_ids = list(set([info['video_id'] for info in all_clip_infos]))
    print(f"\nFound {len(unique_video_ids)} unique video IDs for splitting.")

    # 3. Perform train/validation/test split at the VIDEO CLIP LEVEL
    # First, split into (train+val) and test
    train_val_video_ids, test_video_ids = train_test_split(
        unique_video_ids, test_size=TEST_SPLIT_RATIO, random_state=RANDOM_SEED,
        # Stratify by common pose (e.g., first pose encountered for that video_id) if possible
        # For simplicity now, we assume video_ids are diverse enough for random split.
        # If specific video_ids are all one class, this could be improved.
    )

    # Then, split (train+val) into train and validation
    train_video_ids, val_video_ids = train_test_split(
        train_val_video_ids, test_size=TRAIN_VAL_SPLIT_RATIO, random_state=RANDOM_SEED,
    )

    print(f"\nSplit into: Train Videos ({len(train_video_ids)}), Validation Videos ({len(val_video_ids)}), Test Videos ({len(test_video_ids)})")

    # Map video IDs to their final split type
    final_split_map = {}
    for vid_id in train_video_ids: final_split_map[vid_id] = 'train'
    for vid_id in val_video_ids: final_split_map[vid_id] = 'val'
    for vid_id in test_video_ids: final_split_map[vid_id] = 'test'

    # 4. Generate sequences for each split
    sequence_counter = {'train': 0, 'val': 0, 'test': 0}
    class_name_map = {} # To keep track of class names for final output folders

    for clip_info in all_clip_infos:
        video_id = clip_info['video_id']
        clip_name = clip_info['clip_name']
        df_features_clip = clip_info['df_features'].sort_values(by='frame_index').reset_index(drop=True)
        clip_processed_images_path = clip_info['clip_processed_images_path']
        
        current_final_split_type = final_split_map.get(video_id, None)
        if current_final_split_type is None:
            print(f"  Warning: Video ID {video_id} for clip {clip_name} not assigned a split. Skipping.")
            continue

        num_frames = len(df_features_clip)
        
        # Iterate and create sequences
        for i in range(0, num_frames - SEQUENCE_LENGTH + 1):
            sequence_df = df_features_clip.iloc[i : i + SEQUENCE_LENGTH]
            
            # Ensure all frames in sequence have a label. If any is NaN, skip sequence.
            if sequence_df['label'].isnull().any():
                continue

            # Determine sequence label (e.g., majority vote or the label of the first frame)
            # For yoga poses, likely the label should be consistent across the sequence.
            # You might need to refine this based on your labeling granularity.
            # Here, we take the label of the first frame in the sequence for simplicity.
            # If a single video clip might transition between poses, more complex labeling might be needed.
            sequence_label_idx = int(sequence_df['label'].iloc[0]) # Assuming labels are numerical 0,1,2...

            # Create class_name from index for folder structure
            if sequence_label_idx not in class_name_map:
                # Find class name from the df_labels for a given index (reverse lookup)
                # This needs a mapping of label_idx -> class_name string
                # For now, let's just use "Class_{idx}"
                # You might need a `class_idx_to_name` if your labels are strings initially
                class_name = f"Class_{sequence_label_idx}"
                # If df_labels has original string labels, you can derive it better:
                # class_name = df_labels[df_labels['label']==sequence_label_idx]['original_label_string_column'].iloc[0] # IF YOU HAD ONE
            else:
                class_name = class_name_map[sequence_label_idx]
            
            # Keep a mapping for class names if they're strings in your final dataset
            if sequence_label_idx not in class_name_map:
                class_name_map[sequence_label_idx] = class_name


            final_sequence_dir = os.path.join(final_dataset_root, class_name, f"sequence_{sequence_counter[current_final_split_type]:05d}")
            os.makedirs(final_sequence_dir, exist_ok=True)
            os.makedirs(os.path.join(final_sequence_dir, 'images'), exist_ok=True)

            # Save numerical features for the sequence
            # Only save the numerical feature columns, not clip_id, frame_index, etc.
            numerical_columns = [col for col in sequence_df.columns if col not in ['clip_id', 'frame_index', 'original_image_filename', 'long_original_filename', 'label']]
            sequence_numerical_features = sequence_df[numerical_columns].values
            np.save(os.path.join(final_sequence_dir, 'features.npy'), sequence_numerical_features)

            # Copy annotated images for the sequence
            for frame_original_name in sequence_df['original_image_filename']: # This is 'frame_0000x.jpg'
                annotated_img_src_path = os.path.join(clip_processed_images_path, f"{os.path.splitext(frame_original_name)[0]}_annotated.jpg")
                annotated_img_dst_path = os.path.join(final_sequence_dir, 'images', frame_original_name) # Save with its frame_0000x.jpg name
                shutil.copy(annotated_img_src_path, annotated_img_dst_path)

            sequence_counter[current_final_split_type] += 1
            # print(f"    Generated sequence {sequence_counter[current_final_split_type]-1} for {class_name} in {current_final_split_type} split.")


    print(f"\n--- Final Dataset Creation Complete! ---")
    print(f"Total sequences generated:")
    for split_type, count in sequence_counter.items():
        print(f"  {split_type.capitalize()}: {count} sequences")
    print(f"Dataset saved to: {final_dataset_root}")
    print(f"Class mapping: {class_name_map}")


# --- Run the script ---
if __name__ == "__main__":
    create_dataset_sequences(
        PROCESSED_DATA_ROOT,
        YOUR_LABELED_DATA_CSV,
        RENAMED_DATASET_ROOT, # Pass this to access _frame_map.csv
        FINAL_DATASET_ROOT
    )

